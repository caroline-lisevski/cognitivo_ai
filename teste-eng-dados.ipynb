{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Teste para Engenharia de Dados - Cognitivo AI #\n",
    "\n",
    "## *Autora: Caroline Inês Lisevski* ##\n",
    "\n",
    "A proposta desse trabalho é, a partir de um dataset no formato CSV, identificar os registros que estão deduplicados e realizar processos de modo a permanecer com a entrada mais recente de cada registro. \n",
    "\n",
    "Os requisitos desse trabalho são:\n",
    "\n",
    "-todas as operações devem ser realizadas usando o Spark;\n",
    "\n",
    "-cada operação deverá ser executada no dataframe anterior;\n",
    "\n",
    "-o arquivo final deverá estar em um formato colunar de alta perfomance de leitura;\n",
    "\n",
    "-algumas variáveis deverão ser convertidas, conforme arquivo types_mapping.json.\n",
    "\n",
    "\n",
    "O processamento será local por ter um dataset pequeno. Inicialmente serão importadas as bibliotecas necessárias para o desenvolvimento do trabalho."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importando as bibliotecas necessárias\n",
    "import pandas as pd\n",
    "import findspark #usado para encontrar a instalação do Spark na máquina\n",
    "findspark.init()\n",
    "from pyspark.sql import SparkSession, functions\n",
    "from pyspark.sql.types import TimestampType, IntegerType\n",
    "from pyspark.sql.functions import col\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primeiramente é necessário iniciar uma sessão no Spark e definir que o local de processamento é a máquina que estamos trabalhando ('local[*]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iniciar o spark\n",
    "spark = SparkSession.builder.master('local[*]').getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos usar a biblioteca Pandas para carregar o dataset e, na sequência, esse arquivo será convertido em Spark DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# carregar o dataset e converter ele em spark dataframe \n",
    "data = pd.read_csv(\"data/input/users/load.csv\")\n",
    "df = spark.createDataFrame(data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos olhar o Data Frame usando o comando show( ):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+--------------------+---------------+--------------------+---+--------------------+--------------------+\n",
      "| id|                name|               email|          phone|             address|age|         create_date|         update_date|\n",
      "+---+--------------------+--------------------+---------------+--------------------+---+--------------------+--------------------+\n",
      "|  1|david.lynch@cogni...|         David Lynch|(11) 99999-9997|Mulholland Drive,...| 72|2018-03-03 18:47:...|2018-03-03 18:47:...|\n",
      "|  1|david.lynch@cogni...|         David Lynch|(11) 99999-9998|Mulholland Drive,...| 72|2018-03-03 18:47:...|2018-04-14 17:09:...|\n",
      "|  2|sherlock.holmes@c...|     Sherlock Holmes|(11) 94815-1623|221B Baker Street...| 34|2018-04-21 20:21:...|2018-04-21 20:21:...|\n",
      "|  3|spongebob.squarep...|Spongebob Squarep...|(11) 91234-5678|124 Conch Street,...| 13|2018-05-19 04:07:...|2018-05-19 04:07:...|\n",
      "|  1|david.lynch@cogni...|         David Lynch|(11) 99999-9999|Mulholland Drive,...| 72|2018-03-03 18:47:...|2018-05-23 10:13:...|\n",
      "|  3|spongebob.squarep...|Spongebob Squarep...|(11) 98765-4321|122 Conch Street,...| 13|2018-05-19 04:07:...|2018-05-19 05:08:...|\n",
      "+---+--------------------+--------------------+---------------+--------------------+---+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esse Data Frame possui cinco registros com as variáveis 'id', 'name', 'email', 'phone', 'address', 'age', 'create_date' and 'update_date'. Analisando os registros é possível observar que os dados da variável 'name' estão na variável 'email' e vice-versa. Nesse caso é suficiente apenas renomear as colunas de acordo com as entradas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+--------------------+---------------+--------------------+---+--------------------+--------------------+\n",
      "| id|              e_mail|                name|          phone|             address|age|         create_date|         update_date|\n",
      "+---+--------------------+--------------------+---------------+--------------------+---+--------------------+--------------------+\n",
      "|  1|david.lynch@cogni...|         David Lynch|(11) 99999-9997|Mulholland Drive,...| 72|2018-03-03 18:47:...|2018-03-03 18:47:...|\n",
      "|  1|david.lynch@cogni...|         David Lynch|(11) 99999-9998|Mulholland Drive,...| 72|2018-03-03 18:47:...|2018-04-14 17:09:...|\n",
      "|  2|sherlock.holmes@c...|     Sherlock Holmes|(11) 94815-1623|221B Baker Street...| 34|2018-04-21 20:21:...|2018-04-21 20:21:...|\n",
      "|  3|spongebob.squarep...|Spongebob Squarep...|(11) 91234-5678|124 Conch Street,...| 13|2018-05-19 04:07:...|2018-05-19 04:07:...|\n",
      "|  1|david.lynch@cogni...|         David Lynch|(11) 99999-9999|Mulholland Drive,...| 72|2018-03-03 18:47:...|2018-05-23 10:13:...|\n",
      "|  3|spongebob.squarep...|Spongebob Squarep...|(11) 98765-4321|122 Conch Street,...| 13|2018-05-19 04:07:...|2018-05-19 05:08:...|\n",
      "+---+--------------------+--------------------+---------------+--------------------+---+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.withColumnRenamed(\"name\", \"e_mail\").withColumnRenamed(\"email\", \"name\")\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora vamos ver os tipos de variáveis do Data Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: long (nullable = true)\n",
      " |-- e_mail: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- phone: string (nullable = true)\n",
      " |-- address: string (nullable = true)\n",
      " |-- age: long (nullable = true)\n",
      " |-- create_date: string (nullable = true)\n",
      " |-- update_date: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algumas das variáveis precisam ser convertidas para tipos específicos. O arquivo types_mapping.json nos dá quais variáveis devem ser convertidas e para qual tipo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'age': 'integer', 'create_date': 'timestamp', 'update_date': 'timestamp'}\n"
     ]
    }
   ],
   "source": [
    "#importanto o arquivo json com informações sobre as variáveis que precisam ser convertidas\n",
    "with open('config/types_mapping.json') as mapping:\n",
    "    dados = json.load(mapping)\n",
    "    \n",
    "print(dados)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A variável 'age' deve ser convertida em 'integer' e as variáveis 'create_date' e 'update_date' para 'timestamp'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#alterar a variável age como Integer\n",
    "df = df.withColumn('age', df['age'].cast(IntegerType()))\n",
    "#alterar as variáveis create_date e update_date como Timestamp\n",
    "df = df.withColumn('create_date', df['create_date'].cast(TimestampType()))\n",
    "df = df.withColumn('update_date', df['update_date'].cast(TimestampType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: long (nullable = true)\n",
      " |-- e_mail: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- phone: string (nullable = true)\n",
      " |-- address: string (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- create_date: timestamp (nullable = true)\n",
      " |-- update_date: timestamp (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#verificando se as alterações nas variáveis foram realizadas\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na sequência será feita a filtragem dos dados de modo que seja mantido o dado mais recente ('update_date') para cada 'id'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+--------------------+---------------+--------------------+---+--------------------+--------------------+\n",
      "| id|              e_mail|                name|          phone|             address|age|         create_date|         update_date|\n",
      "+---+--------------------+--------------------+---------------+--------------------+---+--------------------+--------------------+\n",
      "|  1|david.lynch@cogni...|         David Lynch|(11) 99999-9999|Mulholland Drive,...| 72|2018-03-03 18:47:...|2018-05-23 10:13:...|\n",
      "|  2|sherlock.holmes@c...|     Sherlock Holmes|(11) 94815-1623|221B Baker Street...| 34|2018-04-21 20:21:...|2018-04-21 20:21:...|\n",
      "|  3|spongebob.squarep...|Spongebob Squarep...|(11) 98765-4321|122 Conch Street,...| 13|2018-05-19 04:07:...|2018-05-19 05:08:...|\n",
      "+---+--------------------+--------------------+---------------+--------------------+---+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#agrupando dados por id, ordenando update_date de maneira descendente e mantendo os dados mais recentes \n",
    "#de update_date para cada id.\n",
    "\n",
    "df1 = df.orderBy(col('id').asc(),col('update_date').desc()).drop_duplicates(subset=['id'])\n",
    "df1.orderBy('id').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora esses dados serão exportados para um arquivo em formato colunar. Para esse trabalho o formato colunar escolhido foi o Parquet porque ele fornece uma compressão de dados eficiente e também porque o Spark possui suporte em sua biblioteca para o Parquet, o que não exige a instalação de mais bibliotecas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#coverter o arquivo para formato colunar Parquet\n",
    "\n",
    "df1.write.parquet(\"data/output/out.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+--------------------+---------------+--------------------+---+--------------------+--------------------+\n",
      "| id|              e_mail|                name|          phone|             address|age|         create_date|         update_date|\n",
      "+---+--------------------+--------------------+---------------+--------------------+---+--------------------+--------------------+\n",
      "|  1|david.lynch@cogni...|         David Lynch|(11) 99999-9999|Mulholland Drive,...| 72|2018-03-03 18:47:...|2018-05-23 10:13:...|\n",
      "|  2|sherlock.holmes@c...|     Sherlock Holmes|(11) 94815-1623|221B Baker Street...| 34|2018-04-21 20:21:...|2018-04-21 20:21:...|\n",
      "|  3|spongebob.squarep...|Spongebob Squarep...|(11) 98765-4321|122 Conch Street,...| 13|2018-05-19 04:07:...|2018-05-19 05:08:...|\n",
      "+---+--------------------+--------------------+---------------+--------------------+---+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#verificando se o arquivo foi salvo\n",
    "df2 = spark.read.parquet(\"data/output/out.parquet\")\n",
    "df2.orderBy('id').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
